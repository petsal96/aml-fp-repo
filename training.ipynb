{"cells":[{"cell_type":"markdown","id":"75d0ba93-356c-4061-93c4-69bf094e6fc9","metadata":{"id":"75d0ba93-356c-4061-93c4-69bf094e6fc9"},"source":["# Final Project: Segmentation of satellite images"]},{"cell_type":"code","execution_count":null,"id":"gtlbimXDqqTP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":248397,"status":"ok","timestamp":1664915471379,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"gtlbimXDqqTP","outputId":"172fa5a8-cc9c-4665-b048-0527e97ffcc5"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install --upgrade --no-cache-dir gdown\n","!gdown 1TVduwykrR1C_VKx2VJcjmwvJtG4HziA1 # set file id\n","!mkdir /content/data\n","!unzip data128.zip -d data # set correct file name"]},{"cell_type":"markdown","id":"fbacd3e2","metadata":{"id":"fbacd3e2"},"source":["## U-Net"]},{"cell_type":"code","execution_count":null,"id":"c5a64f65","metadata":{"id":"c5a64f65"},"outputs":[],"source":["# necessary imports for U-Net:\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, Cropping2D, BatchNormalization, Activation, Dropout\n","from tensorflow.keras import Model, Input\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import load_img\n","import random\n","import os\n","from PIL import Image\n","import tensorflow.keras.backend as K"]},{"cell_type":"code","execution_count":null,"id":"0d603876","metadata":{"id":"0d603876"},"outputs":[],"source":["def EncoderBlock(prev_layer, filters, dropout_rate=0.0, max_pool=True):\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    if dropout_rate > 0.0:\n","        prev_layer = Dropout(dropout_rate)(prev_layer)\n","    skip_layer = prev_layer\n","    if max_pool:\n","        prev_layer = MaxPool2D()(prev_layer)\n","    return prev_layer, skip_layer\n","    \n","def DecoderBlock(prev_layer, skip_layer, filters, dropout_rate = 0.0):\n","    prev_layer = Conv2DTranspose(filters, 2, strides=2, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    prev_layer = tf.concat([skip_layer, prev_layer], axis=-1)\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    if dropout_rate > 0.0:\n","        prev_layer = Dropout(dropout_rate)(prev_layer)\n","    return prev_layer"]},{"cell_type":"code","execution_count":null,"id":"791c53f0","metadata":{"id":"791c53f0"},"outputs":[],"source":["def UNet(input_size=(128, 128, 3), n_classes=4, dropout_rate=0.0):\n","    inputs = Input(shape = input_size)\n","    enc1 = EncoderBlock(inputs, 64, dropout_rate=dropout_rate, max_pool=True)\n","    enc2 = EncoderBlock(enc1[0], 128, dropout_rate=dropout_rate, max_pool=True)\n","    enc3 = EncoderBlock(enc2[0], 256, dropout_rate=dropout_rate, max_pool=True)\n","    enc4 = EncoderBlock(enc3[0], 512, dropout_rate=dropout_rate, max_pool=True)\n","    enc5 = EncoderBlock(enc4[0], 1024, dropout_rate=dropout_rate, max_pool=False)\n","    dec1 = DecoderBlock(enc5[0], enc4[1], 512, dropout_rate=dropout_rate)\n","    dec2 = DecoderBlock(dec1, enc3[1], 256, dropout_rate=dropout_rate)\n","    dec3 = DecoderBlock(dec2, enc2[1], 128, dropout_rate=dropout_rate)\n","    dec4 = DecoderBlock(dec3, enc1[1], 64, dropout_rate=dropout_rate)\n","    conv = Conv2D(n_classes, 1, activation=\"softmax\", padding=\"same\", kernel_initializer=\"glorot_normal\", bias_initializer=\"zeros\")(dec4)\n","    model = Model(inputs=inputs, outputs=conv)\n","    return model"]},{"cell_type":"markdown","id":"47e16c30","metadata":{"id":"47e16c30"},"source":["## Dataloader"]},{"cell_type":"code","execution_count":null,"id":"5beb0b50","metadata":{"id":"5beb0b50"},"outputs":[],"source":["# define a dataloader for the training pipe:\n","class SatelliteData(tf.keras.utils.Sequence):\n","\n","    FOREST = (4, 135, 29)\n","    FIELDS = (231, 231, 25)\n","    URBAN = (229, 109, 109)\n","    WATER = (14, 10, 214)\n","\n","    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths, shuffle = False):\n","        self.batch_size = batch_size\n","        self.img_size = img_size\n","        if shuffle:\n","            indices = [*range(len(input_img_paths))]\n","            random.shuffle(indices)\n","            self.input_img_paths = np.array(input_img_paths)[indices]\n","            self.target_img_paths = np.array(target_img_paths)[indices]\n","        else:\n","            self.input_img_paths = np.array(input_img_paths)\n","            self.target_img_paths = np.array(target_img_paths)\n","\n","    def __len__(self):\n","        return len(self.target_img_paths) // self.batch_size\n","\n","    def __getitem__(self, idx):\n","        i = idx * self.batch_size\n","        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n","        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n","        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n","        for j, path in enumerate(batch_input_img_paths):\n","            img = load_img(path, target_size=self.img_size)\n","            x[j] = img\n","        y = np.zeros((self.batch_size,) + self.img_size + (4,), dtype=\"float32\")\n","        for j, path in enumerate(batch_target_img_paths):\n","            img = np.array(load_img(path, target_size=self.img_size))\n","            y[j] = np.all(img[:, :, None] == (self.FOREST, self.FIELDS, self.URBAN, self.WATER), axis=-1)\n","        return x, y"]},{"cell_type":"code","execution_count":null,"id":"5264d2e0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":780,"status":"ok","timestamp":1664915481544,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"5264d2e0","outputId":"8dde9507-4bfe-4d54-9f13-84c2445b59e0"},"outputs":[],"source":["data_path = \"data\"\n","drive_path = \"drive/MyDrive/final_project\"\n","train_input_dir = os.path.join(data_path, \"training\", \"images\")\n","train_target_dir = os.path.join(data_path, \"training\", \"annotations\")\n","val_input_dir = os.path.join(data_path, \"validation\", \"images\")\n","val_target_dir = os.path.join(data_path, \"validation\", \"annotations\")\n","\n","train_input_img_paths = [os.path.join(train_input_dir, img) for img in os.listdir(train_input_dir)]\n","train_target_img_paths = [os.path.join(train_target_dir, img) for img in os.listdir(train_target_dir)]\n","\n","val_input_img_paths = [os.path.join(val_input_dir, img) for img in os.listdir(val_input_dir)]\n","val_target_img_paths = [os.path.join(val_target_dir, img) for img in os.listdir(val_target_dir)]\n","\n","print(\"Number of samples:\", len(train_input_img_paths))"]},{"cell_type":"code","execution_count":null,"id":"bdbb904f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"executionInfo":{"elapsed":626,"status":"ok","timestamp":1664915482168,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"bdbb904f","outputId":"e115b24d-8fec-4104-cb21-6819728bdecb"},"outputs":[],"source":["# test dataloader:\n","def transform_to_rgb(ann):\n","    FOREST = (4, 135, 29)\n","    FIELDS = (231, 231, 25)\n","    URBAN = (229, 109, 109)\n","    WATER = (14, 10, 214)\n","    colors = (FOREST, FIELDS, URBAN, WATER)\n","    rgb_ann = np.zeros(ann.shape[:-1] + (3,), dtype=\"uint8\")\n","    for i in range(4):\n","        rgb_ann[ann[:, :, i].astype(bool)] = colors[i]\n","    return rgb_ann\n","\n","img_size = (128, 128)\n","batch_size = 1\n","train_data = SatelliteData(batch_size, img_size, train_input_img_paths, train_target_img_paths, shuffle = True)\n","val_data = SatelliteData(batch_size, img_size, val_input_img_paths, val_target_img_paths, shuffle = True)\n","img, ann = train_data[0]\n","im = Image.fromarray(np.uint8(img[0]), mode=\"RGB\")\n","rgb_an = transform_to_rgb(ann[0])\n","an = Image.fromarray(rgb_an, mode=\"RGB\")\n","display(im)\n","display(an)"]},{"cell_type":"code","execution_count":null,"id":"224246f3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5378,"status":"ok","timestamp":1664915487543,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"224246f3","outputId":"5ce0b9b0-62a3-407e-f24b-e8d119d996c2"},"outputs":[],"source":["# test u-net:\n","model = UNet()\n","model.summary()"]},{"cell_type":"markdown","id":"76c34132","metadata":{"id":"76c34132"},"source":["## Custom loss functions"]},{"cell_type":"code","execution_count":null,"id":"Z0YPgB5mg6Kk","metadata":{"id":"Z0YPgB5mg6Kk"},"outputs":[],"source":["class JaccardLoss: #paper?\n","\n","  def __init__(self, smooth = 1e-5):\n","    self.smooth = smooth\n","\n","  def __call__(self, y_true, y_pred):\n","    intersection = K.sum(y_true * y_pred, axis=(0, 1, 2))\n","    y_true = K.sum(y_true, axis=(0, 1, 2))\n","    y_pred = K.sum(y_pred, axis=(0, 1, 2))\n","    loss = (intersection + self.smooth) / (y_true + y_pred - intersection + self.smooth) \n","    loss = 1.0 - K.mean(loss)\n","    return loss\n","\n","class CategoricalFocalLoss: # cite paper\n","\n","  def __init__(self, gamma = 2.0, alpha = 0.25):\n","    self.gamma = gamma\n","    self.alpha = alpha\n","\n","  def __call__(self, y_true, y_pred):\n","    y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n","    loss = -1.0 * y_true * self.alpha * K.pow(1.0 - y_pred, self.gamma) * K.log(y_pred)\n","    loss = K.mean(loss)\n","    return loss"]},{"cell_type":"code","execution_count":null,"id":"y5PoeMYqjy1a","metadata":{"id":"y5PoeMYqjy1a"},"outputs":[],"source":["class JaccardCoefficient: #paper?\n","\n","  def __init__(self, name = \"jaccard_coefficient\", smooth = 1e-5):\n","    self.__name__ = name\n","    self.smooth = smooth\n","\n","  def __call__(self, y_true, y_pred):\n","    intersection = K.sum(y_true * y_pred, axis=(0, 1, 2))\n","    y_true = K.sum(y_true, axis=(0, 1, 2))\n","    y_pred = K.sum(y_pred, axis=(0, 1, 2))\n","    jaccard = (intersection + self.smooth) / (y_true + y_pred - intersection + self.smooth) \n","    jaccard = K.mean(jaccard)\n","    return jaccard"]},{"cell_type":"markdown","id":"fkr-gEH07W52","metadata":{"id":"fkr-gEH07W52"},"source":["## Custom Callbacks"]},{"cell_type":"code","execution_count":null,"id":"URKBt0YIuqQW","metadata":{"id":"URKBt0YIuqQW"},"outputs":[],"source":["class BestModelCheckPoint(tf.keras.callbacks.Callback):\n","\n","    def __init__(self, dirpath):\n","        self.best_cat_epoch = 0\n","        self.best_jac_epoch = 0\n","        self.best_cat = 0.0\n","        self.best_jac = 0.0\n","        self.dirpath = dirpath\n","        self.best_cat_model = None\n","        self.best_jac_model = None\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if logs[\"val_categorical_accuracy\"] > self.best_cat:\n","            self.best_cat = logs[\"val_categorical_accuracy\"]\n","            self.best_cat_epoch = epoch+1\n","            self.best_cat_model = self.model.get_weights()\n","        if logs[\"val_jaccard_coefficient\"] > self.best_jac:\n","            self.best_jac = logs[\"val_jaccard_coefficient\"]\n","            self.best_jac_epoch = epoch+1\n","            self.best_jac_model = self.model.get_weights()\n","\n","    def on_train_end(self, logs=None):\n","        cat_model_path = os.path.join(self.dirpath, \"cat_model\")\n","        os.mkdir(cat_model_path)\n","        model_path = os.path.join(self.dirpath, \"cat_model\", f\"{self.best_cat_epoch}_{self.best_cat:.4f}\")\n","        self.model.set_weights(self.best_cat_model)\n","        self.model.save_weights(model_path)\n","        jac_model_path = os.path.join(self.dirpath, \"jac_model\")\n","        os.mkdir(jac_model_path)\n","        model_path = os.path.join(jac_model_path, f\"{self.best_jac_epoch}_{self.best_jac:.4f}\")\n","        self.model.set_weights(self.best_jac_model)\n","        self.model.save_weights(model_path)\n","        print(f\"best cat-model saved: {self.best_cat} / {self.best_cat_epoch}, best jac-model saved: {self.best_jac} / {self.best_jac_epoch}\")"]},{"cell_type":"markdown","id":"3f90a798","metadata":{"id":"3f90a798"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"id":"d5d70236","metadata":{},"outputs":[],"source":["batch_sizes = (32, 64)\n","dropout_rates = (0.0, 0.1, 0.3)\n","learning_rates = (0.001, 0.0001, 0.00001)\n","losses = (CategoricalFocalLoss(), JaccardLoss())\n","loss_short_names = (\"focal\", \"jaccard\")\n","img_size = (128, 128)\n","\n","for batch_size in batch_sizes:\n","    for dropout_rate in dropout_rates:\n","        for learning_rate in learning_rates:\n","            for l, loss in enumerate(losses):\n","\n","                train_data = SatelliteData(batch_size, img_size, train_input_img_paths, train_target_img_paths, shuffle = True)\n","                val_data = SatelliteData(batch_size, img_size, val_input_img_paths, val_target_img_paths, shuffle = True)\n","\n","                model_name = \"model128\"\n","                model_name += f\"_bs_{batch_size}\"\n","                model_name += f\"_lr_{learning_rate}\"\n","                model_name += f\"_dr_{dropout_rate}\"\n","                model_name += f\"_loss_{loss_short_names[l]}\"\n","                model_path = os.path.join(drive_path, model_name)\n","                if os.path.exists(model_path):\n","                    continue\n","                os.mkdir(model_path)\n","                os.mkdir(os.path.join(model_path, \"logs\"))\n","\n","                check = BestModelCheckPoint(model_path)\n","                callbacks = [\n","                    check,\n","                    tf.keras.callbacks.TensorBoard(log_dir = os.path.join(model_path, \"logs\"))\n","                ]\n","                model = UNet(input_size = img_size + (3,), dropout_rate = dropout_rate)\n","\n","                model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate), loss = loss, metrics = [tf.keras.metrics.CategoricalAccuracy(), JaccardCoefficient()])\n","                epochs = 30\n","                model.fit(train_data, validation_data = val_data, epochs = epochs, callbacks = callbacks)"]},{"cell_type":"code","execution_count":null,"id":"stEt6c369kO9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4493536,"status":"ok","timestamp":1664143214661,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"stEt6c369kO9","outputId":"7a47d43a-dd16-467c-fd97-cafe111e5c8d"},"outputs":[],"source":["setups = {\"focal\": (64, 0.0, 0.001, CategoricalFocalLoss()), \"jaccard\": (64, 0.0, 0.0001, JaccardLoss())}\n","img_size = (128, 128)\n","epochs = 100\n","\n","for loss_short_name, (batch_size, dropout_rate, learning_rate, loss) in setups.items():\n","\n","    train_data = SatelliteData(batch_size, img_size, train_input_img_paths, train_target_img_paths, shuffle = True)\n","    val_data = SatelliteData(batch_size, img_size, val_input_img_paths, val_target_img_paths, shuffle = True)\n","\n","    model_name = \"final_model128\"\n","    model_name += f\"_bs_{batch_size}\"\n","    model_name += f\"_lr_{learning_rate}\"\n","    model_name += f\"_dr_{dropout_rate}\"\n","    model_name += f\"_loss_{loss_short_name}\"\n","    model_path = os.path.join(drive_path, model_name)\n","    if os.path.exists(model_path):\n","        continue\n","    os.mkdir(model_path)\n","    os.mkdir(os.path.join(model_path, \"logs\"))\n","\n","    check = BestModelCheckPoint(model_path)\n","    callbacks = [\n","        tf.keras.callbacks.EarlyStopping(patience = 5),\n","        check,\n","        tf.keras.callbacks.TensorBoard(log_dir = os.path.join(model_path, \"logs\"))\n","    ]\n","    model = UNet(input_size = img_size + (3,), dropout_rate = dropout_rate)\n","\n","    model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate), loss = loss, metrics = [tf.keras.metrics.CategoricalAccuracy(), JaccardCoefficient()])\n","    model.fit(train_data, validation_data = val_data, epochs = epochs, callbacks = callbacks)"]},{"cell_type":"code","execution_count":null,"id":"rkhdMUxtNkcP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rkhdMUxtNkcP","outputId":"f2aa9aec-28c8-467e-b8c7-cdc7fbd33169"},"outputs":[],"source":["setups = {\"focal\": (64, 0.0, 0.001, CategoricalFocalLoss())}\n","lr_decay_starts = (12,)\n","lr_decay_steps = (1, 3, 6)\n","lr_decays = (0.99, 0.95, 0.9, 0.75, 0.5)\n","img_size = (128, 128)\n","epochs = 200\n","\n","def scheduler(epoch, lr, decay_start, decay_step, decay):\n","  if epoch >= decay_start and (epoch - decay_start) % decay_step == 0:\n","    print(f\"New learning rate: {lr * decay}\")\n","    return lr * decay\n","  else:\n","    return lr\n","\n","for loss_short_name, (batch_size, dropout_rate, learning_rate, loss) in setups.items():\n","  for start in lr_decay_starts:\n","    for step in lr_decay_steps:\n","      for decay in lr_decays:      \n","\n","        train_data = SatelliteData(batch_size, img_size, train_input_img_paths, train_target_img_paths, shuffle = True)\n","        val_data = SatelliteData(batch_size, img_size, val_input_img_paths, val_target_img_paths, shuffle = True)\n","\n","        model_name = \"ffinal_model128\"\n","        model_name += f\"_start_{start}\"\n","        model_name += f\"_step_{step}\"\n","        model_name += f\"_decay_{decay}\"\n","        model_path = os.path.join(drive_path, model_name)\n","        if os.path.exists(model_path):\n","            continue\n","        os.mkdir(model_path)\n","        os.mkdir(os.path.join(model_path, \"logs\"))\n","\n","        check = BestModelCheckPoint(model_path)\n","        lambda_scheduler = lambda epoch, lr, decay_start=start, decay_step=step, decay=decay: scheduler(epoch, lr, decay_start, decay_step, decay)\n","        callbacks = [\n","            tf.keras.callbacks.EarlyStopping(patience = 10),\n","            tf.keras.callbacks.LearningRateScheduler(lambda_scheduler), \n","            check,\n","            tf.keras.callbacks.TensorBoard(log_dir = os.path.join(model_path, \"logs\"))\n","        ]\n","        model = UNet(input_size = img_size + (3,), dropout_rate = dropout_rate)\n","\n","        model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate), loss = loss, metrics = [tf.keras.metrics.CategoricalAccuracy(), JaccardCoefficient()])\n","        model.fit(train_data, validation_data = val_data, epochs = epochs, callbacks = callbacks)"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"provenance":[{"file_id":"1P6oL9fvJVIVR93VAoC91swExUpJTLXgA","timestamp":1663611355748}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.9.13 ('tf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"8149a5070279a1aed96af3f82780a876127b2bdcaa31cc74c4360440f18f9185"}}},"nbformat":4,"nbformat_minor":5}

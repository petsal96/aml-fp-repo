{"cells":[{"cell_type":"markdown","id":"75d0ba93-356c-4061-93c4-69bf094e6fc9","metadata":{"id":"75d0ba93-356c-4061-93c4-69bf094e6fc9"},"source":["# Final Project: Segmentation of satellite images"]},{"cell_type":"markdown","id":"fbacd3e2","metadata":{"id":"fbacd3e2"},"source":["## U-Net"]},{"cell_type":"code","execution_count":null,"id":"c5a64f65","metadata":{"executionInfo":{"elapsed":4324,"status":"ok","timestamp":1662268379429,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"c5a64f65"},"outputs":[],"source":["# necessary imports for U-Net:\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, Cropping2D, BatchNormalization, Activation, Dropout\n","from tensorflow.keras import Model, Input\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import load_img\n","import random\n","import os\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"id":"b02cf53c","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662268379429,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"b02cf53c"},"outputs":[],"source":["def EncoderBlock(prev_layer, filters, dropout_rate=0.0, max_pool=True):\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    if dropout_rate > 0.0:\n","        prev_layer = Dropout(dropout_rate)(prev_layer)\n","    skip_layer = prev_layer\n","    if max_pool:\n","        prev_layer = MaxPool2D()(prev_layer)\n","    return prev_layer, skip_layer\n","    \n","def DecoderBlock(prev_layer, skip_layer, filters, dropout_rate = 0.0):\n","    prev_layer = Conv2DTranspose(filters, 2, strides=2, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    prev_layer = tf.concat([skip_layer, prev_layer], axis=-1)\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    if dropout_rate > 0.0:\n","        prev_layer = Dropout(dropout_rate)(prev_layer)\n","    return prev_layer"]},{"cell_type":"code","execution_count":null,"id":"97897516-1d1f-43e9-82da-e93581f25c91","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662268379430,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"97897516-1d1f-43e9-82da-e93581f25c91"},"outputs":[],"source":["def UNet(input_size=(128, 128, 3), n_classes=4, dropout_rate=0.0):\n","    inputs = Input(shape = input_size)\n","    enc1 = EncoderBlock(inputs, 64, dropout_rate=dropout_rate, max_pool=True)\n","    enc2 = EncoderBlock(enc1[0], 128, dropout_rate=dropout_rate, max_pool=True)\n","    enc3 = EncoderBlock(enc2[0], 256, dropout_rate=dropout_rate, max_pool=True)\n","    enc4 = EncoderBlock(enc3[0], 512, dropout_rate=dropout_rate, max_pool=True)\n","    enc5 = EncoderBlock(enc4[0], 1024, dropout_rate=dropout_rate, max_pool=False)\n","    dec1 = DecoderBlock(enc5[0], enc4[1], 512, dropout_rate=dropout_rate)\n","    dec2 = DecoderBlock(dec1, enc3[1], 256, dropout_rate=dropout_rate)\n","    dec3 = DecoderBlock(dec2, enc2[1], 128, dropout_rate=dropout_rate)\n","    dec4 = DecoderBlock(dec3, enc1[1], 64, dropout_rate=dropout_rate)\n","    conv = Conv2D(n_classes, 1, activation=\"softmax\", padding=\"same\", kernel_initializer=\"glorot_normal\", bias_initializer=\"zeros\")(dec4)\n","    model = Model(inputs=inputs, outputs=conv)\n","    return model"]},{"cell_type":"markdown","id":"47e16c30","metadata":{"id":"47e16c30"},"source":["## Dataloader"]},{"cell_type":"code","execution_count":null,"id":"5beb0b50","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662268379430,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"5beb0b50"},"outputs":[],"source":["# define a dataloader for the training pipe:\n","class SatelliteData(tf.keras.utils.Sequence):\n","\n","    FOREST = (4, 135, 29)\n","    FIELDS = (231, 231, 25)\n","    URBAN = (229, 109, 109)\n","    WATER = (14, 10, 214)\n","\n","    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths, shuffle = False):\n","        self.batch_size = batch_size\n","        self.img_size = img_size\n","        if shuffle:\n","            indices = [*range(len(input_img_paths))]\n","            random.shuffle(indices)\n","            self.input_img_paths = np.array(input_img_paths)[indices]\n","            self.target_img_paths = np.array(target_img_paths)[indices]\n","        else:\n","            self.input_img_paths = np.array(input_img_paths)\n","            self.target_img_paths = np.array(target_img_paths)\n","\n","    def __len__(self):\n","        return len(self.target_img_paths) // self.batch_size\n","\n","    def __getitem__(self, idx):\n","        i = idx * self.batch_size\n","        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n","        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n","        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n","        for j, path in enumerate(batch_input_img_paths):\n","            img = load_img(path, target_size=self.img_size)\n","            x[j] = img\n","        y = np.zeros((self.batch_size,) + self.img_size + (4,), dtype=\"float32\")\n","        for j, path in enumerate(batch_target_img_paths):\n","            img = np.array(load_img(path, target_size=self.img_size))\n","            y[j] = np.all(img[:, :, None] == (self.FOREST, self.FIELDS, self.URBAN, self.WATER), axis=-1)\n","        return x, y"]},{"cell_type":"markdown","id":"3f90a798","metadata":{"id":"3f90a798"},"source":["## Validation"]},{"cell_type":"code","execution_count":null,"id":"a62dc179","metadata":{},"outputs":[],"source":["model_weights = \"\"  # set path to model\n","model = UNet()\n","model.load_weights(model_weights)"]},{"cell_type":"code","execution_count":null,"id":"tM4MUW-sPnJK","metadata":{"executionInfo":{"elapsed":314,"status":"ok","timestamp":1662291778881,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"tM4MUW-sPnJK"},"outputs":[],"source":["def predict(model, img, patch_size, padding):\n","  shift = patch_size - 2 * padding\n","  x_max = (img.shape[1] - 2 * padding) // shift\n","  y_max = (img.shape[0] - 2 * padding) // shift\n","  test_img = []\n","  test_pred = []\n","  for x in range(1, x_max-1):\n","      test_img_row = []\n","      test_pred_row = []\n","      for y in range(1, y_max-1):\n","          img_patch = img[y * shift:y * shift + patch_size, x * shift:x * shift + patch_size, :]\n","          test_img_row.append(img_patch[padding:patch_size - padding, padding:patch_size - padding])\n","          pred = model.predict(img_patch[None, :, :, :])\n","          pred = np.argmax(pred, axis=-1)\n","          pred_patch = np.zeros(pred.shape + (4,))\n","          X, Y, Z = np.ogrid[:pred.shape[0], :pred.shape[1], :pred.shape[2]]\n","          pred_patch[X, Y, Z, pred] = 1\n","          pred_patch = transform_to_rgb(pred_patch[0].reshape((patch_size, patch_size, 4)))\n","          test_pred_row.append(pred_patch[padding:patch_size - padding, padding:patch_size - padding])\n","      test_img.append(np.concatenate(test_img_row, axis=0))\n","      test_pred.append(np.concatenate(test_pred_row, axis=0))\n","  test_img = np.concatenate(test_img, axis=1)\n","  test_pred = np.concatenate(test_pred, axis=1)\n","  return test_img, test_pred\n","\n","def transform_to_rgb(ann):\n","  FOREST = (4, 135, 29)\n","  FIELDS = (231, 231, 25)\n","  URBAN = (229, 109, 109)\n","  WATER = (14, 10, 214)\n","  colors = (FOREST, FIELDS, URBAN, WATER)\n","  rgb_ann = np.zeros(ann.shape[:-1] + (3,), dtype=\"uint8\")\n","  for i in range(4):\n","    rgb_ann[ann[:, :, i].astype(bool)] = colors[i]\n","  return rgb_ann"]},{"cell_type":"code","execution_count":null,"id":"ebb95862","metadata":{},"outputs":[],"source":["test_img = \"\"  # set path to test image\n","img = load_img(os.path.join(test_img))\n","# img = img.resize((img.size[0], img.size[1]))  resize test image if needed\n","img = np.array(img)\n","patch_size = 128\n","padding = 32\n","test_img, test_pred = predict(model, img, patch_size, padding)\n","test_img = Image.fromarray(np.uint8(test_img), mode=\"RGB\")\n","test_pred = Image.fromarray(np.uint8(test_pred), mode=\"RGB\")"]},{"cell_type":"code","execution_count":null,"id":"e1fa73b4","metadata":{},"outputs":[],"source":["img = test_img.convert(\"RGBA\")\n","pred = test_pred.convert(\"RGBA\")\n","\n","final = Image.blend(img, pred, 0.3)\n","final = final.resize((2000, 2000), Image.ANTIALIAS)\n","display(final)\n","final.save(\"\")  # set output path for image"]},{"cell_type":"markdown","id":"0efed0cd","metadata":{},"source":["## Calculate test set errors"]},{"cell_type":"code","execution_count":null,"id":"58b2d0f0","metadata":{},"outputs":[],"source":["import tensorflow.keras.backend as K\n","\n","class JaccardCoefficient:\n","\n","  def __init__(self, name = \"jaccard_coefficient\", smooth = 1e-5):\n","    self.__name__ = name\n","    self.smooth = smooth\n","\n","  def __call__(self, y_true, y_pred):\n","    intersection = K.sum(y_true * y_pred, axis=(0, 1, 2))\n","    y_true = K.sum(y_true, axis=(0, 1, 2))\n","    y_pred = K.sum(y_pred, axis=(0, 1, 2))\n","    jaccard = (intersection + self.smooth) / (y_true + y_pred - intersection + self.smooth) \n","    jaccard = K.mean(jaccard)\n","    return jaccard"]},{"cell_type":"code","execution_count":null,"id":"050ec317","metadata":{},"outputs":[],"source":["test_data_path = \"\"  # set path to test set\n","test_input_path = os.path.join(test_data_path, \"images\")\n","test_target_path = os.path.join(test_data_path, \"annotations\")\n","\n","test_input_img_paths = [os.path.join(test_input_path, img) for img in os.listdir(test_input_path)]\n","test_target_img_paths = [os.path.join(test_target_path, img) for img in os.listdir(test_target_path)]\n","\n","test_data = SatelliteData(64, (128, 128), test_input_img_paths, test_target_img_paths, shuffle = True)"]},{"cell_type":"code","execution_count":null,"id":"d7f25b70","metadata":{},"outputs":[],"source":["cat = tf.keras.metrics.CategoricalAccuracy()\n","jac = JaccardCoefficient()\n","\n","total_cat = 0.0\n","total_jac = 0.0\n","\n","for batch in test_data:\n","    pred = model.predict(batch[0])\n","    total_cat += cat(batch[1], pred)\n","    total_jac += jac(batch[1], pred)\n","\n","total_cat /= len(test_data)\n","total_jac /= len(test_data)\n","\n","print(f\"Categorical accuracy: {total_cat.item():.4f}\")\n","print(f\"Jaccard-coefficient: {total_jac.item():.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"n0lmGMdj3Z4V","metadata":{"id":"n0lmGMdj3Z4V"},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir \"drive/MyDrive/final_project/model01/logs\""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.13 ('tf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"8149a5070279a1aed96af3f82780a876127b2bdcaa31cc74c4360440f18f9185"}}},"nbformat":4,"nbformat_minor":5}

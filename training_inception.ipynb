{"cells":[{"cell_type":"markdown","metadata":{"id":"75d0ba93-356c-4061-93c4-69bf094e6fc9"},"source":["# Final Project: Segmentation of satellite images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190856,"status":"ok","timestamp":1663451756913,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"gtlbimXDqqTP","outputId":"b9c4b5ec-4b83-45d7-fef3-c9e3889a9ba4"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install --upgrade --no-cache-dir gdown\n","!gdown 1TVduwykrR1C_VKx2VJcjmwvJtG4HziA1 # set file id\n","!mkdir /content/data\n","!unzip data128.zip -d data # set correct file name"]},{"cell_type":"markdown","metadata":{"id":"fbacd3e2"},"source":["## U-Net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5a64f65"},"outputs":[],"source":["# necessary imports for U-Net:\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, Cropping2D, BatchNormalization, Activation, Dropout\n","from tensorflow.keras import Model, Input\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import load_img\n","import random\n","import os\n","from PIL import Image\n","import tensorflow.keras.backend as K"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f333953"},"outputs":[],"source":["def InceptionBlock(prev_layer, filters_first, filters_second, filters_third, filters_fourth, dropout_rate=0.0):\n","    first_layer = Conv2D(filters_first, 1, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    first_layer = BatchNormalization()(first_layer)\n","    first_layer = Activation(\"relu\")(first_layer)\n","    second_layer = Conv2D(filters_second[0], 1, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    second_layer = BatchNormalization()(second_layer)\n","    second_layer = Activation(\"relu\")(second_layer)\n","    second_layer = Conv2D(filters_second[1], 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(second_layer)\n","    second_layer = BatchNormalization()(second_layer)\n","    second_layer = Activation(\"relu\")(second_layer)\n","    third_layer = Conv2D(filters_third[0], 1, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    third_layer = BatchNormalization()(third_layer)\n","    third_layer = Activation(\"relu\")(third_layer)\n","    third_layer = Conv2D(filters_third[1], 5, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(third_layer)\n","    third_layer = BatchNormalization()(third_layer)\n","    third_layer = Activation(\"relu\")(third_layer)\n","    fourth_layer = MaxPool2D((3, 3), strides=(1, 1), padding=\"same\")(prev_layer)\n","    fourth_layer = Conv2D(filters_fourth, 5, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(fourth_layer)\n","    fourth_layer = BatchNormalization()(fourth_layer)\n","    fourth_layer = Activation(\"relu\")(fourth_layer)\n","    prev_layer = tf.concat((first_layer, second_layer, third_layer, fourth_layer), axis=-1)\n","    if dropout_rate > 0.0:\n","        prev_layer = Dropout(dropout_rate)(prev_layer)\n","    return prev_layer\n","    \n","def DecoderBlock(prev_layer, skip_layer, filters, dropout_rate = 0.0):\n","    prev_layer = Conv2DTranspose(filters, 2, strides=2, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    prev_layer = tf.concat([skip_layer, prev_layer], axis=-1)\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    prev_layer = Conv2D(filters, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(prev_layer)\n","    prev_layer = BatchNormalization()(prev_layer)\n","    prev_layer = Activation(\"relu\")(prev_layer)\n","    if dropout_rate > 0.0:\n","        prev_layer = Dropout(dropout_rate)(prev_layer)\n","    return prev_layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97897516-1d1f-43e9-82da-e93581f25c91"},"outputs":[],"source":["def UNet(input_size=(128, 128, 3), n_classes=4, dropout_rate=0.0):\n","    inputs = Input(shape = input_size)\n","    enc1 = Conv2D(64, 7, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(inputs)\n","    enc1 = BatchNormalization()(enc1)\n","    enc1 = Activation(\"relu\")(enc1)\n","    if dropout_rate > 0.0:\n","        enc1 = Dropout(dropout_rate)(enc1)\n","    enc2 = MaxPool2D((3, 3), strides=(2, 2), padding=\"same\")(enc1)\n","    enc2 = Conv2D(192, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(enc2)\n","    enc2 = BatchNormalization()(enc2)\n","    enc2 = Activation(\"relu\")(enc2)\n","    enc2 = Conv2D(192, 3, padding=\"same\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(enc2)\n","    enc2 = BatchNormalization()(enc2)\n","    enc2 = Activation(\"relu\")(enc2)\n","    if dropout_rate > 0.0:\n","        enc2 = Dropout(dropout_rate)(enc2)\n","    enc3 = MaxPool2D((3, 3), strides=(2, 2), padding=\"same\")(enc2)\n","    enc3 = InceptionBlock(enc3, 64, (96, 128), (16, 32), 32, dropout_rate=dropout_rate)\n","    enc3 = InceptionBlock(enc3, 128, (128, 192), (32, 96), 64, dropout_rate=dropout_rate)\n","    enc4 = MaxPool2D((3, 3), strides=(2, 2), padding=\"same\")(enc3)\n","    enc4 = InceptionBlock(enc4, 192, (96, 208), (16, 48), 64, dropout_rate=dropout_rate)\n","    enc4 = InceptionBlock(enc4, 160, (112, 224), (24, 64), 64, dropout_rate=dropout_rate)\n","    enc4 = InceptionBlock(enc4, 128, (128, 256), (24, 64), 64, dropout_rate=dropout_rate)\n","    enc4 = InceptionBlock(enc4, 112, (144, 288), (32, 64), 64, dropout_rate=dropout_rate)\n","    enc4 = InceptionBlock(enc4, 256, (160, 320), (32, 128), 128, dropout_rate=dropout_rate)\n","    enc5 = MaxPool2D((3, 3), strides=(2, 2), padding=\"same\")(enc4)\n","    enc5 = InceptionBlock(enc5, 256, (160, 320), (32, 128), 128, dropout_rate=dropout_rate)\n","    enc5 = InceptionBlock(enc5, 384, (192, 384), (48, 128), 128, dropout_rate=dropout_rate)\n","    dec1 = DecoderBlock(enc5, enc4, 832, dropout_rate=dropout_rate)\n","    dec2 = DecoderBlock(dec1, enc3, 480, dropout_rate=dropout_rate)\n","    dec3 = DecoderBlock(dec2, enc2, 192, dropout_rate=dropout_rate)\n","    dec4 = DecoderBlock(dec3, enc1, 64, dropout_rate=dropout_rate)\n","    conv = Conv2D(n_classes, 1, activation=\"softmax\", padding=\"same\", kernel_initializer=\"glorot_normal\", bias_initializer=\"zeros\")(dec4)\n","    model = Model(inputs=inputs, outputs=conv)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"47e16c30"},"source":["## Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5beb0b50"},"outputs":[],"source":["# define a dataloader for the training pipe:\n","class SatelliteData(tf.keras.utils.Sequence):\n","\n","    FOREST = (4, 135, 29)\n","    FIELDS = (231, 231, 25)\n","    URBAN = (229, 109, 109)\n","    WATER = (14, 10, 214)\n","\n","    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths, shuffle = False):\n","        self.batch_size = batch_size\n","        self.img_size = img_size\n","        if shuffle:\n","            indices = [*range(len(input_img_paths))]\n","            random.shuffle(indices)\n","            self.input_img_paths = np.array(input_img_paths)[indices]\n","            self.target_img_paths = np.array(target_img_paths)[indices]\n","        else:\n","            self.input_img_paths = np.array(input_img_paths)\n","            self.target_img_paths = np.array(target_img_paths)\n","\n","    def __len__(self):\n","        return len(self.target_img_paths) // self.batch_size\n","\n","    def __getitem__(self, idx):\n","        i = idx * self.batch_size\n","        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n","        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n","        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n","        for j, path in enumerate(batch_input_img_paths):\n","            img = load_img(path, target_size=self.img_size)\n","            x[j] = img\n","        y = np.zeros((self.batch_size,) + self.img_size + (4,), dtype=\"float32\")\n","        for j, path in enumerate(batch_target_img_paths):\n","            img = np.array(load_img(path, target_size=self.img_size))\n","            y[j] = np.all(img[:, :, None] == (self.FOREST, self.FIELDS, self.URBAN, self.WATER), axis=-1)\n","        return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":596,"status":"ok","timestamp":1663451757506,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"5264d2e0","outputId":"c9e5fdba-8e90-448c-ff38-202916629d65"},"outputs":[],"source":["data_path = \"data\"\n","drive_path = \"drive/MyDrive/final_project\"\n","train_input_dir = os.path.join(data_path, \"training\", \"images\")\n","train_target_dir = os.path.join(data_path, \"training\", \"annotations\")\n","val_input_dir = os.path.join(data_path, \"validation\", \"images\")\n","val_target_dir = os.path.join(data_path, \"validation\", \"annotations\")\n","\n","train_input_img_paths = [os.path.join(train_input_dir, img) for img in os.listdir(train_input_dir)]\n","train_target_img_paths = [os.path.join(train_target_dir, img) for img in os.listdir(train_target_dir)]\n","\n","val_input_img_paths = [os.path.join(val_input_dir, img) for img in os.listdir(val_input_dir)]\n","val_target_img_paths = [os.path.join(val_target_dir, img) for img in os.listdir(val_target_dir)]\n","\n","print(\"Number of samples:\", len(train_input_img_paths))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1663451782509,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"bdbb904f","outputId":"fde58fae-0773-4209-c53a-1bcffc5d3cc8"},"outputs":[],"source":["# test dataloader:\n","def transform_to_rgb(ann):\n","    FOREST = (4, 135, 29)\n","    FIELDS = (231, 231, 25)\n","    URBAN = (229, 109, 109)\n","    WATER = (14, 10, 214)\n","    colors = (FOREST, FIELDS, URBAN, WATER)\n","    rgb_ann = np.zeros(ann.shape[:-1] + (3,), dtype=\"uint8\")\n","    for i in range(4):\n","        rgb_ann[ann[:, :, i].astype(bool)] = colors[i]\n","    return rgb_ann\n","\n","img_size = (128, 128)\n","batch_size = 1\n","train_data = SatelliteData(batch_size, img_size, train_input_img_paths, train_target_img_paths, shuffle = True)\n","val_data = SatelliteData(batch_size, img_size, val_input_img_paths, val_target_img_paths, shuffle = True)\n","img, ann = train_data[0]\n","im = Image.fromarray(np.uint8(img[0]), mode=\"RGB\")\n","rgb_an = transform_to_rgb(ann[0])\n","an = Image.fromarray(rgb_an, mode=\"RGB\")\n","display(im)\n","display(an)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6931,"status":"ok","timestamp":1663451764434,"user":{"displayName":"Petrus Salminen","userId":"07126567515321158789"},"user_tz":-120},"id":"224246f3","outputId":"9e8699d1-c3c5-469f-ff72-e272b2eced13"},"outputs":[],"source":["# test u-net:\n","model = UNet()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"76c34132"},"source":["## Custom loss functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0YPgB5mg6Kk"},"outputs":[],"source":["class JaccardLoss: \n","\n","  def __init__(self, smooth = 1e-5):\n","    self.smooth = smooth\n","\n","  def __call__(self, y_true, y_pred):\n","    intersection = K.sum(y_true * y_pred, axis=(0, 1, 2))\n","    y_true = K.sum(y_true, axis=(0, 1, 2))\n","    y_pred = K.sum(y_pred, axis=(0, 1, 2))\n","    loss = (intersection + self.smooth) / (y_true + y_pred - intersection + self.smooth) \n","    loss = 1.0 - K.mean(loss)\n","    return loss\n","\n","class CategoricalFocalLoss: \n","\n","  def __init__(self, gamma = 2.0, alpha = 0.25):\n","    self.gamma = gamma\n","    self.alpha = alpha\n","\n","  def __call__(self, y_true, y_pred):\n","    y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n","    loss = -1.0 * y_true * self.alpha * K.pow(1.0 - y_pred, self.gamma) * K.log(y_pred)\n","    loss = K.mean(loss)\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5PoeMYqjy1a"},"outputs":[],"source":["class JaccardCoefficient: \n","\n","  def __init__(self, name = \"jaccard_coefficient\", smooth = 1e-5):\n","    self.__name__ = name\n","    self.smooth = smooth\n","\n","  def __call__(self, y_true, y_pred):\n","    intersection = K.sum(y_true * y_pred, axis=(0, 1, 2))\n","    y_true = K.sum(y_true, axis=(0, 1, 2))\n","    y_pred = K.sum(y_pred, axis=(0, 1, 2))\n","    jaccard = (intersection + self.smooth) / (y_true + y_pred - intersection + self.smooth) \n","    jaccard = K.mean(jaccard)\n","    return jaccard"]},{"cell_type":"markdown","metadata":{"id":"fkr-gEH07W52"},"source":["## Custom Callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"URKBt0YIuqQW"},"outputs":[],"source":["class BestModelCheckPoint(tf.keras.callbacks.Callback):\n","\n","    def __init__(self, dirpath):\n","        self.best_cat_epoch = 0\n","        self.best_jac_epoch = 0\n","        self.best_cat = 0.0\n","        self.best_jac = 0.0\n","        self.dirpath = dirpath\n","        self.best_cat_model = None\n","        self.best_jac_model = None\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if logs[\"val_categorical_accuracy\"] > self.best_cat:\n","            self.best_cat = logs[\"val_categorical_accuracy\"]\n","            self.best_cat_epoch = epoch+1\n","            self.best_cat_model = self.model.get_weights()\n","        if logs[\"val_jaccard_coefficient\"] > self.best_jac:\n","            self.best_jac = logs[\"val_jaccard_coefficient\"]\n","            self.best_jac_epoch = epoch+1\n","            self.best_jac_model = self.model.get_weights()\n","\n","    def on_train_end(self, logs=None):\n","        cat_model_path = os.path.join(self.dirpath, \"cat_model\")\n","        os.mkdir(cat_model_path)\n","        model_path = os.path.join(self.dirpath, \"cat_model\", f\"{self.best_cat_epoch}_{self.best_cat:.4f}\")\n","        self.model.set_weights(self.best_cat_model)\n","        self.model.save_weights(model_path)\n","        jac_model_path = os.path.join(self.dirpath, \"jac_model\")\n","        os.mkdir(jac_model_path)\n","        model_path = os.path.join(jac_model_path, f\"{self.best_jac_epoch}_{self.best_jac:.4f}\")\n","        self.model.set_weights(self.best_jac_model)\n","        self.model.save_weights(model_path)\n","        print(f\"best cat-model saved: {self.best_cat} / {self.best_cat_epoch}, best jac-model saved: {self.best_jac} / {self.best_jac_epoch}\")"]},{"cell_type":"markdown","metadata":{"id":"3f90a798"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"stEt6c369kO9"},"outputs":[],"source":["batch_sizes = (32, 64)\n","dropout_rates = (0.0, 0.1, 0.3)\n","learning_rates = (0.001, 0.0001, 0.00001)\n","losses = (CategoricalFocalLoss(), JaccardLoss())\n","loss_short_names = (\"focal\", \"jaccard\")\n","img_size = (128, 128)\n","\n","for batch_size in batch_sizes:\n","    for dropout_rate in dropout_rates:\n","        for learning_rate in learning_rates:\n","            for l, loss in enumerate(losses):\n","\n","                train_data = SatelliteData(batch_size, img_size, train_input_img_paths, train_target_img_paths, shuffle = True)\n","                val_data = SatelliteData(batch_size, img_size, val_input_img_paths, val_target_img_paths, shuffle = True)\n","\n","                model_name = \"inc_model\"\n","                model_name += f\"_bs_{batch_size}\"\n","                model_name += f\"_lr_{learning_rate}\"\n","                model_name += f\"_dr_{dropout_rate}\"\n","                model_name += f\"_loss_{loss_short_names[l]}\"\n","                model_path = os.path.join(drive_path, model_name)\n","                if os.path.exists(model_path):\n","                    continue\n","                os.mkdir(model_path)\n","                os.mkdir(os.path.join(model_path, \"logs\"))\n","\n","                check = BestModelCheckPoint(model_path)\n","                callbacks = [\n","                    check,\n","                    tf.keras.callbacks.TensorBoard(log_dir = os.path.join(model_path, \"logs\"))\n","                ]\n","                model = UNet(input_size = img_size + (3,), dropout_rate = dropout_rate)\n","\n","                model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate), loss = loss, metrics = [tf.keras.metrics.CategoricalAccuracy(), JaccardCoefficient()])\n","                epochs = 30\n","                model.fit(train_data, validation_data = val_data, epochs = epochs, callbacks = callbacks)"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.13 ('tf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"8149a5070279a1aed96af3f82780a876127b2bdcaa31cc74c4360440f18f9185"}}},"nbformat":4,"nbformat_minor":5}
